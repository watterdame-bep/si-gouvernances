# ğŸš€ Migration vers Celery - Fichiers prÃªts Ã  l'emploi

## ğŸ“‹ Vue d'ensemble

Ce document contient tous les fichiers nÃ©cessaires pour migrer vers Celery quand vous serez prÃªt. La logique mÃ©tier reste dans `check_task_deadlines.py`, seul le dÃ©clencheur change.

## ğŸ“¦ Installation

```bash
pip install celery redis
pip freeze > requirements.txt
```

## ğŸ“„ Fichiers Ã  crÃ©er

### 1. `si_gouvernance/celery.py`

```python
"""
Configuration Celery pour SI-Gouvernance
"""
import os
from celery import Celery
from celery.schedules import crontab

# Configuration Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'si_gouvernance.settings')

# CrÃ©er l'application Celery
app = Celery('si_gouvernance')

# Charger la configuration depuis Django settings
app.config_from_object('django.conf:settings', namespace='CELERY')

# DÃ©couvrir automatiquement les tÃ¢ches dans les apps Django
app.autodiscover_tasks()

# Configuration des tÃ¢ches pÃ©riodiques
app.conf.beat_schedule = {
    # VÃ©rification des Ã©chÃ©ances quotidienne Ã  8h00
    'check-task-deadlines-daily': {
        'task': 'core.tasks.check_task_deadlines',
        'schedule': crontab(hour=8, minute=0),
        'options': {
            'expires': 3600,  # Expire aprÃ¨s 1h si pas exÃ©cutÃ©e
        }
    },
    
    # Exemple : Nettoyage des anciennes notifications (optionnel)
    # 'cleanup-old-notifications': {
    #     'task': 'core.tasks.cleanup_old_notifications',
    #     'schedule': crontab(hour=2, minute=0, day_of_week=1),  # Lundi Ã  2h
    # },
}

# Configuration du timezone
app.conf.timezone = 'Europe/Paris'

# Configuration des rÃ©sultats
app.conf.result_expires = 3600  # Les rÃ©sultats expirent aprÃ¨s 1h

# Configuration de la sÃ©rialisation
app.conf.task_serializer = 'json'
app.conf.result_serializer = 'json'
app.conf.accept_content = ['json']

# Configuration du retry
app.conf.task_acks_late = True  # Acknowledge aprÃ¨s exÃ©cution
app.conf.task_reject_on_worker_lost = True  # Rejeter si worker crash

@app.task(bind=True, ignore_result=True)
def debug_task(self):
    """TÃ¢che de debug pour tester Celery"""
    print(f'Request: {self.request!r}')
```

### 2. `core/tasks.py`

```python
"""
TÃ¢ches Celery pour l'application core
"""
from celery import shared_task
from django.core.management import call_command
from django.utils import timezone
import logging

logger = logging.getLogger(__name__)


@shared_task(
    bind=True,
    name='core.tasks.check_task_deadlines',
    max_retries=3,
    default_retry_delay=300  # 5 minutes
)
def check_task_deadlines(self):
    """
    TÃ¢che Celery pour vÃ©rifier les Ã©chÃ©ances des tÃ¢ches
    
    Cette tÃ¢che appelle simplement le management command Django existant,
    ce qui permet de garder toute la logique mÃ©tier au mÃªme endroit.
    
    En cas d'erreur, la tÃ¢che sera rÃ©essayÃ©e 3 fois avec un dÃ©lai de 5 minutes.
    """
    try:
        logger.info("ğŸ” DÃ©marrage de la vÃ©rification des Ã©chÃ©ances")
        
        # Appeler le management command existant
        call_command('check_task_deadlines')
        
        logger.info("âœ… VÃ©rification des Ã©chÃ©ances terminÃ©e avec succÃ¨s")
        return {
            'status': 'success',
            'timestamp': timezone.now().isoformat(),
            'message': 'VÃ©rification des Ã©chÃ©ances terminÃ©e'
        }
        
    except Exception as exc:
        logger.error(f"âŒ Erreur lors de la vÃ©rification des Ã©chÃ©ances: {exc}")
        
        # RÃ©essayer la tÃ¢che
        raise self.retry(exc=exc)


@shared_task(name='core.tasks.cleanup_old_notifications')
def cleanup_old_notifications(days=30):
    """
    TÃ¢che optionnelle pour nettoyer les anciennes notifications
    
    Args:
        days: Nombre de jours Ã  conserver (par dÃ©faut 30)
    """
    try:
        from core.models import NotificationTache
        from datetime import timedelta
        
        date_limite = timezone.now() - timedelta(days=days)
        
        # Supprimer les notifications lues de plus de X jours
        deleted = NotificationTache.objects.filter(
            lue=True,
            date_creation__lt=date_limite
        ).delete()
        
        logger.info(f"ğŸ—‘ï¸ {deleted[0]} notifications supprimÃ©es (plus de {days} jours)")
        
        return {
            'status': 'success',
            'deleted': deleted[0],
            'days': days
        }
        
    except Exception as exc:
        logger.error(f"âŒ Erreur lors du nettoyage: {exc}")
        raise


@shared_task(name='core.tasks.send_daily_summary')
def send_daily_summary():
    """
    TÃ¢che optionnelle pour envoyer un rÃ©sumÃ© quotidien aux chefs de projet
    
    Cette tÃ¢che peut Ãªtre ajoutÃ©e plus tard pour envoyer un email
    avec le rÃ©sumÃ© des tÃ¢ches en cours, en retard, etc.
    """
    # TODO: ImplÃ©menter l'envoi de rÃ©sumÃ© quotidien
    logger.info("ğŸ“§ Envoi du rÃ©sumÃ© quotidien (Ã  implÃ©menter)")
    pass
```

### 3. Modifier `si_gouvernance/__init__.py`

```python
"""
Configuration de l'application SI-Gouvernance
"""

# Importer Celery pour que Django le dÃ©couvre
from .celery import app as celery_app

__all__ = ('celery_app',)
```

### 4. Ajouter dans `settings.py`

```python
# ============================================================================
# CELERY CONFIGURATION
# ============================================================================

# URL du broker (Redis)
CELERY_BROKER_URL = os.environ.get('CELERY_BROKER_URL', 'redis://localhost:6379/0')

# URL du backend de rÃ©sultats
CELERY_RESULT_BACKEND = os.environ.get('CELERY_RESULT_BACKEND', 'redis://localhost:6379/0')

# Formats acceptÃ©s
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'

# Timezone
CELERY_TIMEZONE = 'Europe/Paris'
CELERY_ENABLE_UTC = False

# Configuration des rÃ©sultats
CELERY_RESULT_EXPIRES = 3600  # 1 heure

# Configuration du worker
CELERY_WORKER_PREFETCH_MULTIPLIER = 4
CELERY_WORKER_MAX_TASKS_PER_CHILD = 1000

# Configuration des logs
CELERY_WORKER_LOG_FORMAT = '[%(asctime)s: %(levelname)s/%(processName)s] %(message)s'
CELERY_WORKER_TASK_LOG_FORMAT = '[%(asctime)s: %(levelname)s/%(processName)s] [%(task_name)s(%(task_id)s)] %(message)s'

# Configuration du monitoring
CELERY_SEND_TASK_SENT_EVENT = True
CELERY_TRACK_STARTED = True

# ============================================================================
# LOGGING CONFIGURATION (ajouter Celery)
# ============================================================================

LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {message}',
            'style': '{',
        },
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'verbose',
        },
        'file': {
            'class': 'logging.FileHandler',
            'filename': 'logs/celery.log',
            'formatter': 'verbose',
        },
    },
    'loggers': {
        'celery': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
        },
        'core.tasks': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
        },
    },
}
```

### 5. `.env` (variables d'environnement)

```bash
# Celery Configuration
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Redis Configuration (si nÃ©cessaire)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
```

## ğŸš€ DÃ©marrage

### Installation de Redis

**Windows** :
```bash
# TÃ©lÃ©charger Redis depuis https://github.com/microsoftarchive/redis/releases
# Ou utiliser WSL2 avec Ubuntu
wsl --install
wsl
sudo apt update
sudo apt install redis-server
redis-server
```

**Linux** :
```bash
sudo apt update
sudo apt install redis-server
sudo systemctl start redis
sudo systemctl enable redis
```

**Docker** :
```bash
docker run -d -p 6379:6379 redis:alpine
```

### DÃ©marrage des services

**Terminal 1 : Redis**
```bash
redis-server
```

**Terminal 2 : Celery Worker**
```bash
cd E:\DOCERA\PROJETS\PYTHON\Django\SI-GOUVERNANCE
celery -A si_gouvernance worker -l info --pool=solo
```

**Terminal 3 : Celery Beat (Planificateur)**
```bash
cd E:\DOCERA\PROJETS\PYTHON\Django\SI-GOUVERNANCE
celery -A si_gouvernance beat -l info
```

**Terminal 4 : Django (optionnel)**
```bash
python manage.py runserver
```

### Monitoring avec Flower

```bash
# Installation
pip install flower

# DÃ©marrage
celery -A si_gouvernance flower

# AccÃ¨s : http://localhost:5555
```

## âœ… Tests

### Test 1 : VÃ©rifier que Celery fonctionne

```bash
# Dans Django shell
python manage.py shell

>>> from si_gouvernance.celery import debug_task
>>> result = debug_task.delay()
>>> result.ready()  # True si terminÃ©
>>> result.get()    # RÃ©sultat
```

### Test 2 : Tester la tÃ¢che de vÃ©rification

```bash
# Dans Django shell
python manage.py shell

>>> from core.tasks import check_task_deadlines
>>> result = check_task_deadlines.delay()
>>> result.ready()
>>> result.get()
```

### Test 3 : VÃ©rifier le planning

```bash
# Dans Django shell
python manage.py shell

>>> from si_gouvernance.celery import app
>>> app.conf.beat_schedule
# Doit afficher les tÃ¢ches planifiÃ©es
```

## ğŸ“Š Monitoring

### Logs Celery

```bash
# Voir les logs en temps rÃ©el
tail -f logs/celery.log
```

### Interface Flower

AccÃ©der Ã  http://localhost:5555 pour voir :
- TÃ¢ches en cours
- TÃ¢ches terminÃ©es
- Workers actifs
- Statistiques

### Django Admin (optionnel)

Installer django-celery-results pour voir les rÃ©sultats dans l'admin :

```bash
pip install django-celery-results

# settings.py
INSTALLED_APPS += ['django_celery_results']
CELERY_RESULT_BACKEND = 'django-db'

# Migrations
python manage.py migrate django_celery_results
```

## ğŸ”„ Migration depuis Planificateur Windows

1. **Installer Redis et Celery**
2. **CrÃ©er les fichiers ci-dessus**
3. **Tester en dÃ©veloppement**
4. **DÃ©sactiver le Planificateur Windows**
5. **DÃ©marrer Celery en production**

## ğŸ¯ Avantages de Celery

- âœ… **Asynchrone** : Les tÃ¢ches ne bloquent pas Django
- âœ… **DistribuÃ©** : Peut tourner sur plusieurs serveurs
- âœ… **Retry automatique** : RÃ©essaye en cas d'erreur
- âœ… **Monitoring** : Interface Flower pour voir l'Ã©tat
- âœ… **Scalable** : Ajouter des workers facilement
- âœ… **Multi-plateforme** : Windows, Linux, Mac

## ğŸ“ Checklist de migration

- [ ] Redis installÃ© et dÃ©marrÃ©
- [ ] Celery installÃ© (`pip install celery redis`)
- [ ] Fichiers crÃ©Ã©s (celery.py, tasks.py, __init__.py)
- [ ] Settings.py mis Ã  jour
- [ ] Test du worker : `celery -A si_gouvernance worker -l info`
- [ ] Test du beat : `celery -A si_gouvernance beat -l info`
- [ ] Test de la tÃ¢che : `check_task_deadlines.delay()`
- [ ] Flower installÃ© et testÃ© (optionnel)
- [ ] Planificateur Windows dÃ©sactivÃ©
- [ ] Documentation mise Ã  jour

---

**Date** : 09/02/2026  
**Statut** : PrÃªt pour migration  
**Note** : Tous les fichiers sont prÃªts, il suffit de les crÃ©er quand vous serez prÃªt Ã  migrer
