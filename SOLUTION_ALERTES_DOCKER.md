# Solution Alertes Automatiques dans Docker

## üéØ R√âPONSE √Ä VOTRE QUESTION

**Question**: Si je d√©ploie dans Docker, est-ce que les alertes vont se d√©clencher automatiquement?

**R√©ponse**: ‚ùå NON, pas sans configuration suppl√©mentaire!

Le Planificateur de t√¢ches Windows ne fonctionne pas dans Docker. Il faut utiliser **Celery Beat** √† la place.

---

## üìä COMPARAISON DES SOLUTIONS

| Crit√®re | Windows Task Scheduler | Celery Beat (Docker) |
|---------|------------------------|----------------------|
| **Environnement** | Windows uniquement | Linux/Docker/Production |
| **Configuration** | Interface graphique | Code Python |
| **Portabilit√©** | ‚ùå Non portable | ‚úÖ Portable |
| **Production** | ‚ùå Non recommand√© | ‚úÖ Recommand√© |
| **Complexit√©** | Simple | Moyenne |

---

## ‚úÖ SOLUTION RECOMMAND√âE: CELERY BEAT

Celery Beat est le standard Django pour les t√¢ches planifi√©es en production.

### Avantages
- ‚úÖ Fonctionne dans Docker
- ‚úÖ Portable (Windows, Linux, Mac)
- ‚úÖ Standard de l'industrie
- ‚úÖ Robuste et fiable
- ‚úÖ Monitoring int√©gr√©

---

## üöÄ IMPL√âMENTATION CELERY BEAT

### √âtape 1: Installer les d√©pendances

Ajouter √† `requirements.txt`:
```
celery==5.3.4
redis==5.0.1
django-celery-beat==2.5.0
```

### √âtape 2: Configuration Celery

Cr√©er `si_gouvernance/celery.py`:
```python
import os
from celery import Celery
from celery.schedules import crontab

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'si_gouvernance.settings')

app = Celery('si_gouvernance')
app.config_from_object('django.conf:settings', namespace='CELERY')
app.autodiscover_tasks()

# Configuration des t√¢ches planifi√©es
app.conf.beat_schedule = {
    'check-project-deadlines': {
        'task': 'core.tasks.check_project_deadlines_task',
        'schedule': crontab(hour=9, minute=0),  # 09:00 tous les jours
    },
    'check-stage-delays': {
        'task': 'core.tasks.check_stage_delays_task',
        'schedule': crontab(hour=9, minute=15),  # 09:15 tous les jours
    },
    'check-task-deadlines': {
        'task': 'core.tasks.check_task_deadlines_task',
        'schedule': crontab(hour=9, minute=30),  # 09:30 tous les jours
    },
    'check-budget': {
        'task': 'core.tasks.check_budget_task',
        'schedule': crontab(hour=10, minute=0),  # 10:00 tous les jours
    },
    'check-contract-expiration': {
        'task': 'core.tasks.check_contract_expiration_task',
        'schedule': crontab(hour=10, minute=15),  # 10:15 tous les jours
    },
}
```

### √âtape 3: Cr√©er les t√¢ches Celery

Cr√©er `core/tasks.py`:
```python
from celery import shared_task
from django.core.management import call_command
import logging

logger = logging.getLogger(__name__)

@shared_task
def check_project_deadlines_task():
    """V√©rifie les √©ch√©ances de projets"""
    try:
        call_command('check_project_deadlines')
        logger.info("‚úÖ V√©rification des √©ch√©ances de projets termin√©e")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la v√©rification des √©ch√©ances: {e}")

@shared_task
def check_stage_delays_task():
    """V√©rifie les retards d'√©tapes"""
    try:
        call_command('check_stage_delays')
        logger.info("‚úÖ V√©rification des retards d'√©tapes termin√©e")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la v√©rification des retards d'√©tapes: {e}")

@shared_task
def check_task_deadlines_task():
    """V√©rifie les t√¢ches en retard"""
    try:
        call_command('check_task_deadlines')
        logger.info("‚úÖ V√©rification des t√¢ches en retard termin√©e")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la v√©rification des t√¢ches: {e}")

@shared_task
def check_budget_task():
    """V√©rifie les d√©passements de budget"""
    try:
        call_command('check_budget')
        logger.info("‚úÖ V√©rification des budgets termin√©e")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la v√©rification des budgets: {e}")

@shared_task
def check_contract_expiration_task():
    """V√©rifie les expirations de contrats"""
    try:
        call_command('check_contract_expiration')
        logger.info("‚úÖ V√©rification des contrats termin√©e")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la v√©rification des contrats: {e}")
```

### √âtape 4: Modifier `si_gouvernance/__init__.py`

```python
from .celery import app as celery_app

__all__ = ('celery_app',)
```

### √âtape 5: Configuration Django

Ajouter √† `si_gouvernance/settings.py`:
```python
# Configuration Celery
CELERY_BROKER_URL = 'redis://redis:6379/0'
CELERY_RESULT_BACKEND = 'redis://redis:6379/0'
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = 'Europe/Paris'
CELERY_BEAT_SCHEDULER = 'django_celery_beat.schedulers:DatabaseScheduler'
```

### √âtape 6: Docker Compose

Cr√©er/modifier `docker-compose.yml`:
```yaml
version: '3.8'

services:
  db:
    image: mysql:8.0
    environment:
      MYSQL_DATABASE: si_gouvernance
      MYSQL_ROOT_PASSWORD: root_password
      MYSQL_USER: si_user
      MYSQL_PASSWORD: si_password
    volumes:
      - mysql_data:/var/lib/mysql
    ports:
      - "3306:3306"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  web:
    build: .
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - .:/app
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
    environment:
      - DATABASE_URL=mysql://si_user:si_password@db:3306/si_gouvernance
      - CELERY_BROKER_URL=redis://redis:6379/0

  celery_worker:
    build: .
    command: celery -A si_gouvernance worker --loglevel=info
    volumes:
      - .:/app
    depends_on:
      - db
      - redis
    environment:
      - DATABASE_URL=mysql://si_user:si_password@db:3306/si_gouvernance
      - CELERY_BROKER_URL=redis://redis:6379/0

  celery_beat:
    build: .
    command: celery -A si_gouvernance beat --loglevel=info
    volumes:
      - .:/app
    depends_on:
      - db
      - redis
    environment:
      - DATABASE_URL=mysql://si_user:si_password@db:3306/si_gouvernance
      - CELERY_BROKER_URL=redis://redis:6379/0

volumes:
  mysql_data:
```

### √âtape 7: Dockerfile

Cr√©er `Dockerfile`:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Installer les d√©pendances syst√®me
RUN apt-get update && apt-get install -y \
    gcc \
    default-libmysqlclient-dev \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# Copier les requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copier le projet
COPY . .

# Collecter les fichiers statiques
RUN python manage.py collectstatic --noinput

EXPOSE 8000

CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]
```

---

## üéØ D√âMARRAGE

### 1. Installer les d√©pendances
```bash
pip install -r requirements.txt
```

### 2. Appliquer les migrations
```bash
python manage.py migrate
```

### 3. D√©marrer Docker Compose
```bash
docker-compose up -d
```

### 4. V√©rifier que tout fonctionne
```bash
# V√©rifier les conteneurs
docker-compose ps

# V√©rifier les logs de Celery Beat
docker-compose logs -f celery_beat

# V√©rifier les logs du worker
docker-compose logs -f celery_worker
```

---

## üìã PLANIFICATION DES T√ÇCHES

Les t√¢ches s'ex√©cuteront automatiquement:

| Heure | T√¢che | Description |
|-------|-------|-------------|
| 09:00 | check_project_deadlines | √âch√©ances J-7, J-3, J-1, retards |
| 09:15 | check_stage_delays | Retards d'√©tapes |
| 09:30 | check_task_deadlines | T√¢ches en retard |
| 10:00 | check_budget | D√©passements de budget |
| 10:15 | check_contract_expiration | Expirations de contrats |

---

## üîç MONITORING

### V√©rifier les t√¢ches planifi√©es
```bash
# Entrer dans le conteneur
docker-compose exec web python manage.py shell

# Lister les t√¢ches
from django_celery_beat.models import PeriodicTask
for task in PeriodicTask.objects.all():
    print(f"{task.name}: {task.enabled}")
```

### Voir les logs en temps r√©el
```bash
# Logs de Celery Beat (planificateur)
docker-compose logs -f celery_beat

# Logs du worker (ex√©cution)
docker-compose logs -f celery_worker

# Logs de l'application
docker-compose logs -f web
```

### Tester manuellement une t√¢che
```bash
docker-compose exec web python manage.py shell

from core.tasks import check_project_deadlines_task
check_project_deadlines_task.delay()
```

---

## ‚úÖ AVANTAGES DE CETTE SOLUTION

1. **Portable**: Fonctionne partout (Windows, Linux, Mac, Cloud)
2. **Production-ready**: Standard de l'industrie
3. **Robuste**: Retry automatique en cas d'erreur
4. **Monitoring**: Logs d√©taill√©s et interface d'administration
5. **Scalable**: Peut g√©rer des milliers de t√¢ches
6. **Flexible**: Facile de modifier les horaires

---

## üÜö COMPARAISON AVEC WINDOWS TASK SCHEDULER

### Windows Task Scheduler (Solution actuelle)
```
‚úÖ Simple √† configurer (interface graphique)
‚úÖ Pas de d√©pendances suppl√©mentaires
‚ùå Windows uniquement
‚ùå Pas portable
‚ùå Difficile √† versionner
‚ùå Pas adapt√© pour Docker/Production
```

### Celery Beat (Solution recommand√©e)
```
‚úÖ Portable (tous OS)
‚úÖ Production-ready
‚úÖ Versionnable (code)
‚úÖ Fonctionne dans Docker
‚úÖ Monitoring int√©gr√©
‚úÖ Standard de l'industrie
‚ö†Ô∏è N√©cessite Redis
‚ö†Ô∏è Configuration plus complexe
```

---

## üéØ RECOMMANDATION

### Pour le d√©veloppement local sur Windows
- ‚úÖ Utiliser le Planificateur de t√¢ches Windows (solution actuelle)
- Simple et rapide √† mettre en place

### Pour Docker / Production
- ‚úÖ Utiliser Celery Beat (solution recommand√©e)
- Standard de l'industrie, robuste et portable

---

## üìù R√âSUM√â

**Question**: Les alertes se d√©clenchent-elles automatiquement dans Docker?

**R√©ponse**: 
- ‚ùå Non, pas avec le Planificateur Windows
- ‚úÖ Oui, avec Celery Beat (configuration n√©cessaire)

**Solution**: Impl√©menter Celery Beat pour Docker (voir ci-dessus)

**Temps d'impl√©mentation**: ~30 minutes

**Complexit√©**: Moyenne (mais standard de l'industrie)

---

## üöÄ PROCHAINES √âTAPES

1. D√©cider de l'environnement de d√©ploiement:
   - Local Windows ‚Üí Garder Task Scheduler
   - Docker/Production ‚Üí Impl√©menter Celery Beat

2. Si Docker, suivre les √©tapes ci-dessus

3. Tester les t√¢ches planifi√©es

4. Monitorer les logs

---

**Le syst√®me de notifications est pr√™t, il ne manque que le planificateur adapt√© √† votre environnement!** üéâ
